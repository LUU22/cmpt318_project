{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "#import datetime\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nets import nets_factory\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(label):\n",
    "    r = np.zeros(total_labels, dtype=int)\n",
    "    r[label] = 1\n",
    "    return r.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iter(data, batch_size, num_epochs, shuffle=False):\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    # 每个epoch的num_batch\n",
    "    num_batches_per_epoch = int((len(data) - 1) / batch_size) + 1\n",
    "    print(\"num_batches_per_epoch:\",num_batches_per_epoch)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_data[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/final_data.pkl')\n",
    "index = data.columns.values\n",
    "data_length = data.shape[0]\n",
    "\n",
    "weather_type = set(data['Weather'])\n",
    "weather_dict = dict(zip(weather_type,list(range(len(weather_type)))))\n",
    "\n",
    "total_labels = len(weather_type)\n",
    "\n",
    "\n",
    "data['Weather'].replace(pd.Series(weather_dict), inplace=True)\n",
    "\n",
    "#data['Weather'] = data['Weather'].update(pd.Series(weather_dict))\n",
    "data['Weather'] = data['Weather'].apply(one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clear                        17\n",
       "Cloudy                        4\n",
       "Drizzle,Fog                  13\n",
       "Fog                           7\n",
       "Freezing Fog                  8\n",
       "Mainly Clear                 10\n",
       "Moderate Snow,Fog             2\n",
       "Mostly Cloudy                16\n",
       "Rain                         11\n",
       "Rain Showers                  3\n",
       "Rain Showers,Snow Showers     0\n",
       "Rain,Drizzle,Fog              1\n",
       "Rain,Fog                      9\n",
       "Rain,Snow                    15\n",
       "Rain,Snow,Fog                12\n",
       "Snow                          5\n",
       "Snow Showers                  6\n",
       "Snow,Fog                     14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(weather_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(pd.Series(weather_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[index[-1]].values\n",
    "y = data[index[-2]].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "x_train = x_train / 256.0\n",
    "x_test  = x_test  / 256.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "num_epochs = 20\n",
    "\n",
    "num_labels = len(weather_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define 2 placeholders\n",
    "x = tf.placeholder(tf.float32, [None, 224, 224,3], name=\"input_x\")\n",
    "y = tf.placeholder(tf.float32, [None, num_labels], name=\"input_y\")\n",
    "\n",
    "train_network_fn = nets_factory.get_network_fn('alexnet_v2', \n",
    "                                                num_classes = num_labels, \n",
    "                                                weight_decay = 0.0005,\n",
    "                                                is_training = True,\n",
    "                                                \n",
    "                                                )\n",
    "# Adapted code from https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim/python/slim/nets\n",
    "\n",
    "prediction, end_points = train_network_fn(x)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 0.00001\n",
    "decay_steps = 5000\n",
    "decay_rate = 0.95\n",
    "    \n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, decay_steps=decay_steps, \n",
    "                                           decay_rate=decay_rate, staircase=True)\n",
    "    #optimizer = tf.GradientDescent(learning_rate)\n",
    "    #optimizer.minimize(...my loss..., global_step=global_step)\n",
    "\n",
    "\n",
    "add_global = global_step.assign_add(1)\n",
    "with tf.control_dependencies([add_global]):\n",
    "    #train_op = opt.minimise(loss)\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(prediction,1))\n",
    "\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_list = [[],[],[], []] #[[iterater],[training_accuracy],[testing_accuracy], [loss]]\n",
    "test_array = np.array(list(zip(x_test,y_test)))\n",
    "test_array = test_array[:100]\n",
    "x_t, y_t = zip(*test_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches_per_epoch: 131\n",
      "iterator 10, testing accuracy 0.2000 , training accuracy 0.2750\n",
      "iterator 20, testing accuracy 0.2000 , training accuracy 0.3250\n",
      "iterator 30, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 40, testing accuracy 0.1800 , training accuracy 0.1500\n",
      "iterator 50, testing accuracy 0.2400 , training accuracy 0.2500\n",
      "iterator 60, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 70, testing accuracy 0.2100 , training accuracy 0.1750\n",
      "iterator 80, testing accuracy 0.2000 , training accuracy 0.3500\n",
      "iterator 90, testing accuracy 0.2300 , training accuracy 0.2000\n",
      "iterator 100, testing accuracy 0.2500 , training accuracy 0.0750\n",
      "iterator 110, testing accuracy 0.1500 , training accuracy 0.2500\n",
      "iterator 120, testing accuracy 0.1700 , training accuracy 0.1500\n",
      "iterator 130, testing accuracy 0.2300 , training accuracy 0.3250\n",
      "iterator 140, testing accuracy 0.2300 , training accuracy 0.2750\n",
      "iterator 150, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 160, testing accuracy 0.2100 , training accuracy 0.2000\n",
      "iterator 170, testing accuracy 0.2100 , training accuracy 0.1750\n",
      "iterator 180, testing accuracy 0.2000 , training accuracy 0.1250\n",
      "iterator 190, testing accuracy 0.1500 , training accuracy 0.0750\n",
      "iterator 200, testing accuracy 0.2000 , training accuracy 0.4000\n",
      "iterator 210, testing accuracy 0.2000 , training accuracy 0.2000\n",
      "iterator 220, testing accuracy 0.2200 , training accuracy 0.2250\n",
      "iterator 230, testing accuracy 0.1800 , training accuracy 0.2250\n",
      "iterator 240, testing accuracy 0.1900 , training accuracy 0.2000\n",
      "iterator 250, testing accuracy 0.1800 , training accuracy 0.1500\n",
      "iterator 260, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 270, testing accuracy 0.2000 , training accuracy 0.2000\n",
      "iterator 280, testing accuracy 0.2000 , training accuracy 0.2000\n",
      "iterator 290, testing accuracy 0.2100 , training accuracy 0.2250\n",
      "iterator 300, testing accuracy 0.2000 , training accuracy 0.0500\n",
      "iterator 310, testing accuracy 0.2100 , training accuracy 0.1250\n",
      "iterator 320, testing accuracy 0.2300 , training accuracy 0.2000\n",
      "iterator 330, testing accuracy 0.1800 , training accuracy 0.1750\n",
      "iterator 340, testing accuracy 0.1900 , training accuracy 0.3000\n",
      "iterator 350, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 360, testing accuracy 0.1700 , training accuracy 0.2750\n",
      "iterator 370, testing accuracy 0.2500 , training accuracy 0.2500\n",
      "iterator 380, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 390, testing accuracy 0.2200 , training accuracy 0.2500\n",
      "iterator 400, testing accuracy 0.1600 , training accuracy 0.2250\n",
      "iterator 410, testing accuracy 0.1900 , training accuracy 0.3750\n",
      "iterator 420, testing accuracy 0.1900 , training accuracy 0.3000\n",
      "iterator 430, testing accuracy 0.1600 , training accuracy 0.2250\n",
      "iterator 440, testing accuracy 0.2000 , training accuracy 0.2000\n",
      "iterator 450, testing accuracy 0.2000 , training accuracy 0.1000\n",
      "iterator 460, testing accuracy 0.2200 , training accuracy 0.2000\n",
      "iterator 470, testing accuracy 0.2100 , training accuracy 0.2000\n",
      "iterator 480, testing accuracy 0.1900 , training accuracy 0.2750\n",
      "iterator 490, testing accuracy 0.1900 , training accuracy 0.1750\n",
      "iterator 500, testing accuracy 0.1700 , training accuracy 0.2750\n",
      "iterator 510, testing accuracy 0.2300 , training accuracy 0.1500\n",
      "iterator 520, testing accuracy 0.1300 , training accuracy 0.1000\n",
      "iterator 530, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 540, testing accuracy 0.1900 , training accuracy 0.2000\n",
      "iterator 550, testing accuracy 0.2000 , training accuracy 0.2000\n",
      "iterator 560, testing accuracy 0.1800 , training accuracy 0.1500\n",
      "iterator 570, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 580, testing accuracy 0.2200 , training accuracy 0.2000\n",
      "iterator 590, testing accuracy 0.1400 , training accuracy 0.1000\n",
      "iterator 600, testing accuracy 0.2100 , training accuracy 0.1250\n",
      "iterator 610, testing accuracy 0.2000 , training accuracy 0.3000\n",
      "iterator 620, testing accuracy 0.2600 , training accuracy 0.1250\n",
      "iterator 630, testing accuracy 0.1600 , training accuracy 0.2500\n",
      "iterator 640, testing accuracy 0.2300 , training accuracy 0.1500\n",
      "iterator 650, testing accuracy 0.1200 , training accuracy 0.1000\n",
      "iterator 660, testing accuracy 0.2100 , training accuracy 0.1500\n",
      "iterator 670, testing accuracy 0.1900 , training accuracy 0.3750\n",
      "iterator 680, testing accuracy 0.2000 , training accuracy 0.3000\n",
      "iterator 690, testing accuracy 0.2000 , training accuracy 0.2750\n",
      "iterator 700, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 710, testing accuracy 0.2200 , training accuracy 0.2500\n",
      "iterator 720, testing accuracy 0.2700 , training accuracy 0.1500\n",
      "iterator 730, testing accuracy 0.2300 , training accuracy 0.2500\n",
      "iterator 740, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 750, testing accuracy 0.1800 , training accuracy 0.1500\n",
      "iterator 760, testing accuracy 0.2000 , training accuracy 0.1500\n",
      "iterator 770, testing accuracy 0.1900 , training accuracy 0.1000\n",
      "iterator 780, testing accuracy 0.1800 , training accuracy 0.1250\n",
      "iterator 790, testing accuracy 0.2000 , training accuracy 0.2000\n",
      "iterator 800, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 810, testing accuracy 0.2000 , training accuracy 0.1000\n",
      "iterator 820, testing accuracy 0.2000 , training accuracy 0.2500\n",
      "iterator 830, testing accuracy 0.1700 , training accuracy 0.2250\n",
      "iterator 840, testing accuracy 0.1900 , training accuracy 0.2000\n",
      "iterator 850, testing accuracy 0.2400 , training accuracy 0.2250\n",
      "iterator 860, testing accuracy 0.2200 , training accuracy 0.4000\n",
      "iterator 870, testing accuracy 0.1900 , training accuracy 0.2000\n",
      "iterator 880, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 890, testing accuracy 0.2200 , training accuracy 0.0750\n",
      "iterator 900, testing accuracy 0.2100 , training accuracy 0.1500\n",
      "iterator 910, testing accuracy 0.2000 , training accuracy 0.2000\n",
      "iterator 920, testing accuracy 0.2100 , training accuracy 0.2500\n",
      "iterator 930, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 940, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 950, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 960, testing accuracy 0.2300 , training accuracy 0.3500\n",
      "iterator 970, testing accuracy 0.2400 , training accuracy 0.1750\n",
      "iterator 980, testing accuracy 0.2400 , training accuracy 0.1750\n",
      "iterator 990, testing accuracy 0.2100 , training accuracy 0.2750\n",
      "iterator 1000, testing accuracy 0.2000 , training accuracy 0.2000\n",
      "iterator 1010, testing accuracy 0.1800 , training accuracy 0.2500\n",
      "iterator 1020, testing accuracy 0.2300 , training accuracy 0.1750\n",
      "iterator 1030, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 1040, testing accuracy 0.1400 , training accuracy 0.2000\n",
      "iterator 1050, testing accuracy 0.2600 , training accuracy 0.2500\n",
      "iterator 1060, testing accuracy 0.2300 , training accuracy 0.3750\n",
      "iterator 1070, testing accuracy 0.2000 , training accuracy 0.2750\n",
      "iterator 1080, testing accuracy 0.2100 , training accuracy 0.2250\n",
      "iterator 1090, testing accuracy 0.1900 , training accuracy 0.0750\n",
      "iterator 1100, testing accuracy 0.2100 , training accuracy 0.1750\n",
      "iterator 1110, testing accuracy 0.1900 , training accuracy 0.2750\n",
      "iterator 1120, testing accuracy 0.1700 , training accuracy 0.1750\n",
      "iterator 1130, testing accuracy 0.2000 , training accuracy 0.2500\n",
      "iterator 1140, testing accuracy 0.1900 , training accuracy 0.2000\n",
      "iterator 1150, testing accuracy 0.2300 , training accuracy 0.1750\n",
      "iterator 1160, testing accuracy 0.2000 , training accuracy 0.1000\n",
      "iterator 1170, testing accuracy 0.1900 , training accuracy 0.2250\n",
      "iterator 1180, testing accuracy 0.1700 , training accuracy 0.2750\n",
      "iterator 1190, testing accuracy 0.1800 , training accuracy 0.2500\n",
      "iterator 1200, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 1210, testing accuracy 0.2000 , training accuracy 0.2500\n",
      "iterator 1220, testing accuracy 0.1700 , training accuracy 0.1750\n",
      "iterator 1230, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 1240, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 1250, testing accuracy 0.1900 , training accuracy 0.3500\n",
      "iterator 1260, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 1270, testing accuracy 0.2100 , training accuracy 0.3500\n",
      "iterator 1280, testing accuracy 0.2100 , training accuracy 0.2250\n",
      "iterator 1290, testing accuracy 0.1400 , training accuracy 0.2250\n",
      "iterator 1300, testing accuracy 0.1900 , training accuracy 0.1500\n",
      "iterator 1310, testing accuracy 0.2000 , training accuracy 0.2000\n",
      "iterator 1320, testing accuracy 0.1800 , training accuracy 0.2500\n",
      "iterator 1330, testing accuracy 0.2000 , training accuracy 0.3500\n",
      "iterator 1340, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 1350, testing accuracy 0.1700 , training accuracy 0.1000\n",
      "iterator 1360, testing accuracy 0.1600 , training accuracy 0.2750\n",
      "iterator 1370, testing accuracy 0.1600 , training accuracy 0.3000\n",
      "iterator 1380, testing accuracy 0.2100 , training accuracy 0.1750\n",
      "iterator 1390, testing accuracy 0.2000 , training accuracy 0.3250\n",
      "iterator 1400, testing accuracy 0.2100 , training accuracy 0.1750\n",
      "iterator 1410, testing accuracy 0.1500 , training accuracy 0.2000\n",
      "iterator 1420, testing accuracy 0.2500 , training accuracy 0.1500\n",
      "iterator 1430, testing accuracy 0.1600 , training accuracy 0.2750\n",
      "iterator 1440, testing accuracy 0.1900 , training accuracy 0.1750\n",
      "iterator 1450, testing accuracy 0.2100 , training accuracy 0.2500\n",
      "iterator 1460, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 1470, testing accuracy 0.2000 , training accuracy 0.2000\n",
      "iterator 1480, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 1490, testing accuracy 0.1400 , training accuracy 0.2500\n",
      "iterator 1500, testing accuracy 0.2200 , training accuracy 0.0750\n",
      "iterator 1510, testing accuracy 0.2200 , training accuracy 0.3750\n",
      "iterator 1520, testing accuracy 0.2100 , training accuracy 0.1750\n",
      "iterator 1530, testing accuracy 0.1900 , training accuracy 0.2000\n",
      "iterator 1540, testing accuracy 0.1800 , training accuracy 0.2000\n",
      "iterator 1550, testing accuracy 0.2700 , training accuracy 0.1750\n",
      "iterator 1560, testing accuracy 0.2300 , training accuracy 0.2000\n",
      "iterator 1570, testing accuracy 0.1700 , training accuracy 0.1750\n",
      "iterator 1580, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 1590, testing accuracy 0.2000 , training accuracy 0.2000\n",
      "iterator 1600, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 1610, testing accuracy 0.2000 , training accuracy 0.0750\n",
      "iterator 1620, testing accuracy 0.2300 , training accuracy 0.3000\n",
      "iterator 1630, testing accuracy 0.2200 , training accuracy 0.2000\n",
      "iterator 1640, testing accuracy 0.2400 , training accuracy 0.2750\n",
      "iterator 1650, testing accuracy 0.2200 , training accuracy 0.3000\n",
      "iterator 1660, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 1670, testing accuracy 0.2000 , training accuracy 0.3000\n",
      "iterator 1680, testing accuracy 0.2200 , training accuracy 0.2500\n",
      "iterator 1690, testing accuracy 0.2400 , training accuracy 0.2000\n",
      "iterator 1700, testing accuracy 0.1700 , training accuracy 0.2250\n",
      "iterator 1710, testing accuracy 0.1800 , training accuracy 0.2000\n",
      "iterator 1720, testing accuracy 0.2100 , training accuracy 0.3500\n",
      "iterator 1730, testing accuracy 0.2000 , training accuracy 0.3000\n",
      "iterator 1740, testing accuracy 0.2000 , training accuracy 0.2000\n",
      "iterator 1750, testing accuracy 0.2300 , training accuracy 0.2000\n",
      "iterator 1760, testing accuracy 0.1700 , training accuracy 0.2250\n",
      "iterator 1770, testing accuracy 0.2500 , training accuracy 0.1500\n",
      "iterator 1780, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 1790, testing accuracy 0.2100 , training accuracy 0.2500\n",
      "iterator 1800, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 1810, testing accuracy 0.1700 , training accuracy 0.1750\n",
      "iterator 1820, testing accuracy 0.2200 , training accuracy 0.3250\n",
      "iterator 1830, testing accuracy 0.2100 , training accuracy 0.1000\n",
      "iterator 1840, testing accuracy 0.2200 , training accuracy 0.1500\n",
      "iterator 1850, testing accuracy 0.1900 , training accuracy 0.2000\n",
      "iterator 1860, testing accuracy 0.2100 , training accuracy 0.2000\n",
      "iterator 1870, testing accuracy 0.1900 , training accuracy 0.1500\n",
      "iterator 1880, testing accuracy 0.2100 , training accuracy 0.1250\n",
      "iterator 1890, testing accuracy 0.2500 , training accuracy 0.1500\n",
      "iterator 1900, testing accuracy 0.1700 , training accuracy 0.1500\n",
      "iterator 1910, testing accuracy 0.2300 , training accuracy 0.1250\n",
      "iterator 1920, testing accuracy 0.2000 , training accuracy 0.3000\n",
      "iterator 1930, testing accuracy 0.1800 , training accuracy 0.1500\n",
      "iterator 1940, testing accuracy 0.1900 , training accuracy 0.3500\n",
      "iterator 1950, testing accuracy 0.2100 , training accuracy 0.2250\n",
      "iterator 1960, testing accuracy 0.2600 , training accuracy 0.1000\n",
      "iterator 1970, testing accuracy 0.2100 , training accuracy 0.2250\n",
      "iterator 1980, testing accuracy 0.2000 , training accuracy 0.4000\n",
      "iterator 1990, testing accuracy 0.2000 , training accuracy 0.3000\n",
      "iterator 2000, testing accuracy 0.2000 , training accuracy 0.2750\n",
      "iterator 2010, testing accuracy 0.2000 , training accuracy 0.1500\n",
      "iterator 2020, testing accuracy 0.1600 , training accuracy 0.2000\n",
      "iterator 2030, testing accuracy 0.1400 , training accuracy 0.1750\n",
      "iterator 2040, testing accuracy 0.1800 , training accuracy 0.2750\n",
      "iterator 2050, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 2060, testing accuracy 0.2200 , training accuracy 0.1500\n",
      "iterator 2070, testing accuracy 0.1900 , training accuracy 0.2750\n",
      "iterator 2080, testing accuracy 0.1900 , training accuracy 0.2000\n",
      "iterator 2090, testing accuracy 0.2200 , training accuracy 0.1750\n",
      "iterator 2100, testing accuracy 0.2600 , training accuracy 0.0750\n",
      "iterator 2110, testing accuracy 0.2200 , training accuracy 0.2000\n",
      "iterator 2120, testing accuracy 0.2000 , training accuracy 0.1250\n",
      "iterator 2130, testing accuracy 0.2000 , training accuracy 0.2500\n",
      "iterator 2140, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 2150, testing accuracy 0.2200 , training accuracy 0.1750\n",
      "iterator 2160, testing accuracy 0.2500 , training accuracy 0.2000\n",
      "iterator 2170, testing accuracy 0.2200 , training accuracy 0.3500\n",
      "iterator 2180, testing accuracy 0.1800 , training accuracy 0.2000\n",
      "iterator 2190, testing accuracy 0.2100 , training accuracy 0.2250\n",
      "iterator 2200, testing accuracy 0.1700 , training accuracy 0.2000\n",
      "iterator 2210, testing accuracy 0.2600 , training accuracy 0.2000\n",
      "iterator 2220, testing accuracy 0.1700 , training accuracy 0.2000\n",
      "iterator 2230, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 2240, testing accuracy 0.2200 , training accuracy 0.1500\n",
      "iterator 2250, testing accuracy 0.2000 , training accuracy 0.2000\n",
      "iterator 2260, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 2270, testing accuracy 0.1900 , training accuracy 0.3250\n",
      "iterator 2280, testing accuracy 0.2500 , training accuracy 0.2500\n",
      "iterator 2290, testing accuracy 0.1400 , training accuracy 0.2000\n",
      "iterator 2300, testing accuracy 0.2300 , training accuracy 0.1500\n",
      "iterator 2310, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 2320, testing accuracy 0.2000 , training accuracy 0.2500\n",
      "iterator 2330, testing accuracy 0.2100 , training accuracy 0.1750\n",
      "iterator 2340, testing accuracy 0.2100 , training accuracy 0.2250\n",
      "iterator 2350, testing accuracy 0.2300 , training accuracy 0.2250\n",
      "iterator 2360, testing accuracy 0.1900 , training accuracy 0.3250\n",
      "iterator 2370, testing accuracy 0.2000 , training accuracy 0.3750\n",
      "iterator 2380, testing accuracy 0.2000 , training accuracy 0.2750\n",
      "iterator 2390, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 2400, testing accuracy 0.2200 , training accuracy 0.1500\n",
      "iterator 2410, testing accuracy 0.2200 , training accuracy 0.2750\n",
      "iterator 2420, testing accuracy 0.1900 , training accuracy 0.2000\n",
      "iterator 2430, testing accuracy 0.2400 , training accuracy 0.1250\n",
      "iterator 2440, testing accuracy 0.1900 , training accuracy 0.2500\n",
      "iterator 2450, testing accuracy 0.2100 , training accuracy 0.2000\n",
      "iterator 2460, testing accuracy 0.2300 , training accuracy 0.2750\n",
      "iterator 2470, testing accuracy 0.2100 , training accuracy 0.2250\n",
      "iterator 2480, testing accuracy 0.1800 , training accuracy 0.1750\n",
      "iterator 2490, testing accuracy 0.2200 , training accuracy 0.3500\n",
      "iterator 2500, testing accuracy 0.2200 , training accuracy 0.2250\n",
      "iterator 2510, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 2520, testing accuracy 0.2000 , training accuracy 0.2500\n",
      "iterator 2530, testing accuracy 0.2000 , training accuracy 0.1750\n",
      "iterator 2540, testing accuracy 0.2100 , training accuracy 0.3000\n",
      "iterator 2550, testing accuracy 0.2100 , training accuracy 0.1500\n",
      "iterator 2560, testing accuracy 0.2000 , training accuracy 0.2500\n",
      "iterator 2570, testing accuracy 0.2000 , training accuracy 0.2250\n",
      "iterator 2580, testing accuracy 0.2300 , training accuracy 0.3250\n",
      "iterator 2590, testing accuracy 0.1700 , training accuracy 0.3000\n",
      "iterator 2600, testing accuracy 0.1900 , training accuracy 0.1000\n",
      "iterator 2610, testing accuracy 0.2200 , training accuracy 0.2000\n",
      "iterator 2620, testing accuracy 0.1800 , training accuracy 0.2571\n",
      "iterator 2620, testing accuracy 0.1800 , training accuracy 0.2571\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(1)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "     \n",
    "    batches = batch_iter(list(zip(x_train, y_train)), batch_size, num_epochs)\n",
    "    i = 0\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord = coord)\n",
    "    for batch in batches:\n",
    "        i = i + 1\n",
    "        x_batch, y_batch = zip(*batch)\n",
    "        sess.run(train_step, feed_dict={x:x_batch, y:y_batch})\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "\n",
    "            acc_train = sess.run(accuracy, feed_dict = {x:x_batch, y:y_batch})\n",
    "            acc_test = sess.run(accuracy, feed_dict = {x:x_t, y:y_t})\n",
    "            #ts = sess.run(global_step)\n",
    "            #lr = sess.run(learning_rate)\n",
    "            result_list[0].append(i)\n",
    "            result_list[1].append(acc_train)\n",
    "            result_list[2].append(acc_test)\n",
    "            print(\"iterator \" + str(i) + \", testing accuracy %.4f\" % acc_test , \n",
    "                  \", training accuracy %.4f\" % acc_train #, \n",
    "                  #\", learning rate %f\" % lr \n",
    "                 )\n",
    "    print(\"iterator \" + str(i) + \", testing accuracy %.4f\" % acc_test , \n",
    "                  \", training accuracy %.4f\" % acc_train #, \n",
    "                  #\", learning rate %f\" % lr \n",
    "                 )\n",
    "    save_path = saver.save(sess, \"/home/leo/Desktop/cmpt318_project/model/alexnet_model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Define a net\n",
    "2. Prediction\n",
    "3. Loss\n",
    "4. Optimizer\n",
    "5. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(result_list[0], result_list[1])\n",
    "plt.plot(result_list[0], result_list[2])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train accuracy', 'Test accuracy'])\n",
    "plt.savefig('alexnet_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15,  0, 16,  3, 17,  3,  0,  3,  5,  5,  0,  3,  3, 11, 16,  3, 10,\n",
       "       10, 10,  0,  2, 10, 17,  3, 13,  0, 15,  5, 13,  3, 13,  0,  5, 17,\n",
       "        3, 16,  8,  1, 10, 17, 13, 10, 17,  3,  5, 10,  5,  8, 11, 11, 13,\n",
       "       13, 10, 13, 11,  0,  3, 11, 17, 10, 17, 17,  3,  0, 13, 16, 16, 13,\n",
       "        3, 10, 17,  5, 13, 11,  3,  9, 13, 13, 13,  0,  6,  3, 17,  0,  0,\n",
       "        6, 10,  5,  3, 17,  5,  5,  5, 10,  0,  3, 10, 10, 13, 11])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_t,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
